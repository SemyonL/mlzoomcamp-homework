{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64d1c8db",
   "metadata": {},
   "source": [
    "# Module 3. Homework: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "da4db007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "bdcc6e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd31379",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e92812cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                  object\n",
       "industry                     object\n",
       "number_of_courses_viewed      int64\n",
       "annual_income               float64\n",
       "employment_status            object\n",
       "location                     object\n",
       "interaction_count             int64\n",
       "lead_score                  float64\n",
       "converted                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5c2433f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6ed61be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "numerical = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "y_col = ['converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "81c39bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical] = df[categorical].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "ddb28c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numerical] = df[numerical].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c13c745f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32616c72",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "What is the most frequent observation (mode) for the column `industry`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "86726f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    retail\n",
       "Name: industry, dtype: object"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.industry.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744ef37",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Create the [correlation matrix](https://www.google.com/search?q=correlation+matrix) for the numerical features of your dataset.\n",
    "In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "\n",
    "What are the two features that have the biggest correlation?\n",
    "\n",
    "- `interaction_count` and `lead_score`\n",
    "- `number_of_courses_viewed` and `lead_score`\n",
    "- `number_of_courses_viewed` and `interaction_count`\n",
    "- `annual_income` and `interaction_count`\n",
    "\n",
    "Only consider the pairs above when answering this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7e7143b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_courses_viewed\n",
      "number_of_courses_viewed    1.000000\n",
      "interaction_count           0.023565\n",
      "annual_income               0.009770\n",
      "lead_score                  0.004879\n",
      "dtype: float64\n",
      "\n",
      "annual_income\n",
      "annual_income               1.000000\n",
      "interaction_count           0.027036\n",
      "lead_score                  0.015610\n",
      "number_of_courses_viewed    0.009770\n",
      "dtype: float64\n",
      "\n",
      "interaction_count\n",
      "interaction_count           1.000000\n",
      "annual_income               0.027036\n",
      "number_of_courses_viewed    0.023565\n",
      "lead_score                  0.009888\n",
      "dtype: float64\n",
      "\n",
      "lead_score\n",
      "lead_score                  1.000000\n",
      "annual_income               0.015610\n",
      "interaction_count           0.009888\n",
      "number_of_courses_viewed    0.004879\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in numerical:\n",
    "    print(c)\n",
    "    print(df[numerical].corrwith(df[c]).abs().sort_values(ascending=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72cc0d3",
   "metadata": {},
   "source": [
    "\n",
    "number_of_courses_viewed  \n",
    "interaction_count           0.023565  \n",
    "lead_score                  0.004879  \n",
    "\n",
    "**annual_income**  \n",
    "**interaction_count           0.027036**  \n",
    "\n",
    "interaction_count  \n",
    "lead_score                  0.009888  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b986f6",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "45cd3f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)\n",
    "\n",
    "ys = []\n",
    "for d in [df_full_train, df_train, df_val, df_test]:\n",
    "    d.reset_index(inplace=True, drop=True)\n",
    "    col = 'converted'\n",
    "    ys.append(d[col].values)\n",
    "    del d[col]\n",
    "\n",
    "y_full_train, y_train, y_val, y_test = ys\n",
    "del ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd7d0a9",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "- Calculate the mutual information score between `converted` and other categorical variables in the dataset. Use the training set only.\n",
    "- Round the scores to 2 decimals using `round(score, 2)`.\n",
    "\n",
    "Which of these variables has the biggest mutual information score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "05baed7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source          0.035396\n",
       "employment_status    0.012938\n",
       "industry             0.011575\n",
       "location             0.004464\n",
       "dtype: float64"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "def mutual_info_converted_score(series):\n",
    "    return mutual_info_score(series, y_train)\n",
    "\n",
    "mi = df_train[categorical].apply(mutual_info_converted_score)\n",
    "mi.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173d4e41",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "- Now let's train a logistic regression.\n",
    "- Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "- Fit the model on the training dataset.\n",
    "  - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "  - `model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)`\n",
    "- Calculate the accuracy on the validation dataset and round it to 2 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "720a0994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_val = dv.transform(df_val[categorical + numerical].to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a9b2d1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "decisions = (y_pred >= 0.5)\n",
    "(y_val == decisions).mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97311e1",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "- Let's find the least useful feature using the _feature elimination_ technique.\n",
    "- Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "\n",
    "Which of following feature has the smallest difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b1f0830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check = ['industry', 'employment_status', 'lead_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "135e1852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current: 0.6996587030716723\n",
      "\n",
      "industry\n",
      "current: 0.6996587030716723\n",
      "diff: 0.0\n",
      "\n",
      "employment_status\n",
      "current: 0.6962457337883959\n",
      "diff: 0.0034129692832763903\n",
      "\n",
      "lead_score\n",
      "current: 0.7064846416382252\n",
      "diff: 0.0068259385665528916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model_without_feature_and_get_accuracy(feature_to_exclude):\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    features = [x for x in categorical + numerical if x != feature_to_exclude]\n",
    "    X_train = dv.fit_transform(df_train[features].to_dict(orient='records'))\n",
    "    X_val = dv.transform(df_val[features].to_dict(orient='records'))\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_val)[:,1]\n",
    "    decisions = (y_pred >= 0.5)\n",
    "    return (y_val == decisions).mean()\n",
    "\n",
    "accuracy = train_model_without_feature_and_get_accuracy(None)\n",
    "print(f'current: {accuracy}')\n",
    "print()\n",
    "\n",
    "for f in features_to_check:\n",
    "    print(f)\n",
    "    current_accuracy = train_model_without_feature_and_get_accuracy(f)\n",
    "    print(f'current: {current_accuracy}')\n",
    "    print(f'diff: {abs(accuracy - current_accuracy)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5fe517",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "- Now let's train a regularized logistic regression.\n",
    "- Let's try the following values of the parameter `C`: `[0.01, 0.1, 1, 10, 100]`.\n",
    "- Train models using all the features as in Q4.\n",
    "- Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "\n",
    "Which of these `C` leads to the best accuracy on the validation set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "54447f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current C: 0.01\n",
      "accuracy: 0.7\n",
      "\n",
      "current C: 0.1\n",
      "accuracy: 0.7\n",
      "\n",
      "current C: 1\n",
      "accuracy: 0.7\n",
      "\n",
      "current C: 10\n",
      "accuracy: 0.7\n",
      "\n",
      "current C: 100\n",
      "accuracy: 0.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model_with_c_and_get_accuracy(reg):\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(df_train.to_dict(orient='records'))\n",
    "    X_val = dv.transform(df_val.to_dict(orient='records'))\n",
    "    model = LogisticRegression(solver='liblinear', C=reg, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_val)[:,1]\n",
    "    decisions = (y_pred >= 0.5)\n",
    "    return (y_val == decisions).mean()\n",
    "\n",
    "for c in [0.01, 0.1, 1, 10, 100]:\n",
    "    print(f'current C: {c}')\n",
    "    print(f'accuracy: {train_model_with_c_and_get_accuracy(c).round(3)}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
